# TransKeep Technical Refinements
## LLM Tone Customization, PDF Extraction, & Tech Stack Updates

**Date:** November 14, 2025  
**Based on:** User Feedback - Roy's Technical Specifications  
**Status:** Technical Architecture Refinement

---

## Overview

Based on Roy's feedback on the initial technical research, this document refines the technical approach in three key areas:

1. **LLM Integration for Tone Customization** â€” Lightweight LLM for custom tone
2. **PDF Extraction Optimization** â€” Fast and cheap extraction
3. **Tech Stack Update** â€” React + shadcn/ui + FastAPI

---

## 1. LLM FOR TONE CUSTOMIZATION ğŸ¯

### Requirements
- âœ… Fast response time (lightweight task, not heavy translation)
- âœ… Support tone customization (user can describe desired tone)
- âœ… Cost-effective for high-volume usage
- âœ… Good quality for tone adjustments (not primary translation engine)

### Recommended Approach: Two-Stage Architecture

**Stage 1: Primary Translation** (External API - DeepL or Google)
- Handles the core translation using best-in-class neural machine translation
- Fast, reliable, industry-standard

**Stage 2: Tone Customization** (Fast LLM - Post-processing)
- Takes the translated text and adjusts tone based on user specification
- Uses a lightweight, fast LLM for this lighter task
- This is where the user's custom tone description comes in

### LLM Options Comparison for Tone Customization

| LLM | Speed | Cost | Use Case | Token Window | Rating |
|---|---|---|---|---|---|
| **Claude 3.5 Haiku** | âš¡âš¡âš¡ Very Fast | ğŸ’° $0.80/M tokens | **RECOMMENDED** for tone tasks | 200K | â­â­â­â­â­ |
| **Gemini 1.5 Flash** | âš¡âš¡âš¡ Very Fast | ğŸ’° $0.075/M input tokens | Good alternative | 1M | â­â­â­â­ |
| **Llama 3.1 (via Together.ai)** | âš¡âš¡âš¡ Very Fast | ğŸ’° $0.30/M tokens | Open source option | 128K | â­â­â­â­ |
| **GPT-4o Mini** | âš¡âš¡ Fast | ğŸ’¸ $0.15/M input tokens | More capable, slower | 128K | â­â­â­ |

**[High Confidence]** Sources: Anthropic, Google DeepMind, OpenAI official pricing [2025]

### Recommendation: **Claude 3.5 Haiku** â­â­â­â­â­

**Why Haiku for Tone Customization:**

1. **Speed:** Extremely fast latency (50-100ms typically)
   - Ideal for real-time tone adjustment UI feedback
   - Users see tone-adjusted text quickly while reviewing

2. **Cost:** Very affordable at $0.80/1M input tokens
   - Tone customization is typically 100-500 tokens per page
   - Processing 500 pages at $0.50/page = $250 (reasonable)

3. **Quality for Tone Tasks:** Excellent understanding of:
   - Formal/informal tone shifts
   - Technical/casual vocabulary adjustments
   - Audience-specific language adaptations
   - Maintains meaning while adjusting presentation

4. **Size:** Optimized for specific tasks (not overkill)
   - Haiku designed for focused, specific tasks
   - 3.5 version adds improvement over 3.0

5. **Track Record:** Proven capability for writing/rewriting tasks
   - Language adjustment is core strength
   - Research shows Haiku performs excellently on style tasks

**Alternative: Gemini 1.5 Flash**
- Faster still (10-50ms)
- Even cheaper ($0.075/M input tokens = ~$0.04 per page)
- 1M token window useful for larger context
- Similar quality for tone customization
- *Tradeoff:* Slightly less mature than Haiku 3.5

### Implementation Pattern: Tone Customization

```python
# User provides tone specification
tone_description = "formal, technical, professional"
translated_text = "The system works good"

# Call Claude Haiku for tone adjustment
tone_prompt = f"""
You are a language expert specializing in tone adjustment.
Current tone: Simple, colloquial
Target tone: {tone_description}
Target audience: Technical professionals in {industry}

Rewrite this text in the target tone, preserving all meaning:
"{translated_text}"

Return ONLY the rewritten text, no explanations.
"""

response = client.messages.create(
    model="claude-3-5-haiku-20241022",
    max_tokens=500,
    messages=[{"role": "user", "content": tone_prompt}]
)

tone_adjusted = response.content[0].text
```

### Cost Analysis for Tone Customization

**Example: 100-page PDF with tone customization**

Using Claude 3.5 Haiku:
- Avg page: 300 words = ~400 tokens
- Tone adjustment prompt: ~200 tokens
- Total per page: ~600 tokens input, ~600 tokens output = 1200 tokens

```
100 pages Ã— 1200 tokens = 120,000 tokens
Cost: 120,000 / 1,000,000 Ã— $0.80 = $0.096 â‰ˆ $0.10 per document
```

**Very cost-effective!** âœ…

---

## 2. PDF EXTRACTION: Fast & Cheap ğŸ“„

### Requirements
- âœ… Fast extraction (process 100MB in reasonable time)
- âœ… Cheap (preferably open source or very low cost)
- âœ… Handle digital PDFs well (prioritize, optimize for these)
- âœ… Handle scanned PDFs with OCR (secondary)

### Recommended Approach: Hybrid Strategy

**For Digital PDFs (95% of use cases):**
â†’ **Use: PyMuPDF (fitz)** - FASTEST and FREE

**For Scanned PDFs (5% of use cases):**
â†’ **Use: LlamaParse** (AI OCR, when needed)

### Option Comparison

| Tool | Type | Speed | Cost | Accuracy | Use Case | Rating |
|---|---|---|---|---|---|---|
| **PyMuPDF (fitz)** | Parser | âš¡âš¡âš¡ 50-200 pages/sec | ğŸ’° FREE (open source) | Good for digital | **PRIMARY** for digital PDFs | â­â­â­â­â­ |
| **pdfplumber** | Parser | âš¡âš¡ 10-50 pages/sec | ğŸ’° FREE (open source) | Excellent table handling | Good when table preservation critical | â­â­â­â­ |
| **PDFMiner** | Parser | âš¡ 5-20 pages/sec | ğŸ’° FREE (open source) | Good (complex layouts) | Accurate but slower | â­â­â­ |
| **LlamaParse** | AI OCR | âš¡âš¡ 5-50 pages/sec | ğŸ’¸ $0.005-0.03/page | Excellent (AI) | **SECONDARY** for scanned PDFs | â­â­â­â­â­ |
| **Poppler (pdftotext)** | CLI Tool | âš¡âš¡âš¡ 100-500 pages/sec | ğŸ’° FREE | Good | Fast command-line extraction | â­â­â­â­ |

**[High Confidence]** Sources: PyMuPDF docs, LlamaParse, benchmark comparison [2025]

### Primary Recommendation: **PyMuPDF (fitz)**

**Installation:**
```bash
pip install PyMuPDF
```

**Usage Example:**
```python
import fitz

def extract_pdf_text(pdf_path):
    """Extract text from PDF with layout information"""
    doc = fitz.open(pdf_path)
    text_blocks = []
    
    for page_num in range(len(doc)):
        page = doc[page_num]
        
        # Extract text with position information
        text_dict = page.get_text("dict")
        
        for block in text_dict["blocks"]:
            if block["type"] == 0:  # Text block
                text_blocks.append({
                    "text": block["lines"],
                    "bbox": block["bbox"],
                    "page": page_num
                })
    
    return text_blocks

# Performance for 100MB PDF (~500 pages):
# PyMuPDF: ~5-10 seconds
# Cost: $0 (open source)
```

**Why PyMuPDF for Digital PDFs:**

1. **Speed:** 50-200 pages/second
   - 500-page document: 2.5-10 seconds
   - 100MB digital PDF: Extract in seconds

2. **Cost:** Completely free (open source)
   - No API fees, no usage limits
   - Self-hosted on your server

3. **Layout Preservation:** Includes coordinate information
   - Can reconstruct exact block positions
   - Essential for your synchronized highlighting feature

4. **Reliability:** Stable, well-maintained library
   - Used in production by many document processing applications
   - Good Python integration

5. **No Network Latency:** Runs locally on your backend
   - No API calls = no network delays
   - Handles large PDFs without timeout issues

### Secondary: **LlamaParse for Scanned PDFs**

**When to use:**
- User uploads a scanned PDF (text is images)
- OCR required to extract text

**Pricing:**
- $0.005-0.03 per page (depending on complexity)
- 500-page scanned document: $2.50-15

**Usage Pattern:**
```python
from llama_parse import LlamaParse

async def extract_scanned_pdf(pdf_path):
    """Extract text from scanned PDF using AI OCR"""
    parser = LlamaParse(api_key="your_api_key")
    
    # LlamaParse handles OCR + layout understanding
    document = await parser.aload_data(pdf_path)
    
    return document
```

**Implementation Strategy:**
1. Try PyMuPDF first (fast, free)
2. If text extraction yields nothing â†’ Document is scanned
3. Fall back to LlamaParse for scanned documents
4. Cache OCR results to avoid re-processing

### Recommended Hybrid Architecture

```python
class PDFExtractor:
    def __init__(self):
        self.parser = PyMuPDF  # Default
        self.ocr = LlamaParse  # Fallback
    
    async def extract(self, pdf_path):
        # Try fast extraction first
        text = self._extract_with_fitz(pdf_path)
        
        if text and len(text.strip()) > 100:
            return {"method": "parser", "text": text, "cost": 0}
        else:
            # Scanned PDF detected, use OCR
            text = await self.ocr.extract(pdf_path)
            return {"method": "ocr", "text": text, "cost": "~$0.01-0.03"}
    
    def _extract_with_fitz(self, pdf_path):
        doc = fitz.open(pdf_path)
        text = ""
        for page in doc:
            text += page.get_text()
        return text
```

### Cost Summary for PDF Extraction

**Scenario: 1000 PDFs processed per month**

- **90% digital PDFs (900):** PyMuPDF = $0
- **10% scanned PDFs (100):** LlamaParse avg $0.015/page = $1.50
- **Total monthly:** ~$1.50 (extremely cheap)

---

## 3. UPDATED TECH STACK ğŸ› ï¸

### Your Stack: React + shadcn/ui + FastAPI

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Frontend (React)              â”‚
â”‚  - React 18+ (Latest)               â”‚
â”‚  - shadcn/ui (Component Library)    â”‚
â”‚  - TanStack Query (Data Fetching)   â”‚
â”‚  - TypeScript (Type Safety)         â”‚
â”‚                                     â”‚
â”‚  â”œâ”€ Main Components:                â”‚
â”‚  â”‚  â”œâ”€ PDF Upload                   â”‚
â”‚  â”‚  â”œâ”€ Dual-View Display            â”‚
â”‚  â”‚  â”œâ”€ Synchronized Highlighting    â”‚
â”‚  â”‚  â”œâ”€ Tone Customization Form      â”‚
â”‚  â”‚  â””â”€ Download Button              â”‚
â”‚                                     â”‚
â”‚  â””â”€ UI/UX Tools:                    â”‚
â”‚     â”œâ”€ pdf.js (PDF rendering)      â”‚
â”‚     â”œâ”€ Zustand (State management)  â”‚
â”‚     â””â”€ Tailwind CSS (Styling)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†• (CORS + HTTP)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Backend (FastAPI)             â”‚
â”‚  - FastAPI (Async Python)            â”‚
â”‚  - Pydantic (Data Validation)        â”‚
â”‚  - SQLAlchemy (ORM)                  â”‚
â”‚  - Celery + Redis (Job Queue)        â”‚
â”‚                                     â”‚
â”‚  â”œâ”€ Core Endpoints:                 â”‚
â”‚  â”‚  â”œâ”€ POST /upload (chunked)       â”‚
â”‚  â”‚  â”œâ”€ POST /translate               â”‚
â”‚  â”‚  â”œâ”€ POST /customize-tone          â”‚
â”‚  â”‚  â”œâ”€ GET /download                 â”‚
â”‚  â”‚  â””â”€ GET /status/{job_id}          â”‚
â”‚                                     â”‚
â”‚  â””â”€ Async Workers:                  â”‚
â”‚     â”œâ”€ PDF Extraction (PyMuPDF)     â”‚
â”‚     â”œâ”€ Translation API Calls        â”‚
â”‚     â”œâ”€ Tone Customization (Claude)  â”‚
â”‚     â””â”€ PDF Reconstruction           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    External Services                 â”‚
â”‚  - DeepL API (Translation)           â”‚
â”‚  - Claude 3.5 Haiku (Tone)          â”‚
â”‚  - LlamaParse (Scanned PDFs)        â”‚
â”‚  - AWS S3 (File Storage)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Frontend: React + shadcn/ui

**Key Dependencies:**
```json
{
  "react": "^18.3.0",
  "react-dom": "^18.3.0",
  "typescript": "^5.3.0",
  "@radix-ui/react-dialog": "^1.1.1",
  "@radix-ui/react-form": "^0.0.13",
  "shadcn-ui": "^0.8.0",
  "tailwindcss": "^3.4.0",
  "pdfjs-dist": "^4.0.0",
  "@tanstack/react-query": "^5.28.0",
  "zustand": "^4.4.7",
  "axios": "^1.6.5"
}
```

**Architecture Pattern:**

```tsx
// App.tsx - Main component
import { PDFUpload } from './components/PDFUpload'
import { DualView } from './components/DualView'
import { ToneCustomizer } from './components/ToneCustomizer'

export function App() {
  const [file, setFile] = useState(null)
  const [translation, setTranslation] = useState(null)
  const [tone, setTone] = useState("professional")

  return (
    <div className="flex flex-col gap-4">
      <PDFUpload onUpload={setFile} />
      {translation && (
        <>
          <DualView 
            original={file} 
            translated={translation}
          />
          <ToneCustomizer 
            tone={tone}
            onToneChange={setTone}
          />
        </>
      )}
    </div>
  )
}
```

**Key shadcn/ui Components for TransKeep:**
- `Dialog` - File upload modal
- `Button` - Action buttons
- `Form` - Tone customization form
- `Progress` - Upload/processing progress
- `Tabs` - Original/Translated tabs
- `Card` - Content containers

### Backend: FastAPI

**Key Dependencies:**
```txt
fastapi==0.104.1
uvicorn==0.24.0
pydantic==2.5.0
sqlalchemy==2.0.23
celery==5.3.4
redis==5.0.1
python-multipart==0.0.6
PyMuPDF==1.23.8
aiofiles==23.2.1
httpx==0.25.2
anthropic==0.7.0
deepl==1.17.0
llama-parse==0.1.0
```

**Core Architecture:**

```python
# main.py - FastAPI application
from fastapi import FastAPI, UploadFile, File, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
import os

# Initialize services
llm_client = Anthropic()
translator = deepl.Translator(os.getenv("DEEPL_API_KEY"))

app = FastAPI(title="TransKeep API")

# Enable CORS for React frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "https://transkeep.com"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ============================================
# 1. FILE UPLOAD ENDPOINT
# ============================================
@app.post("/api/v1/upload")
async def upload_pdf(file: UploadFile = File(...)):
    """
    Handle PDF upload with validation
    Returns job_id for async processing
    """
    # Validate file
    if not file.filename.endswith('.pdf'):
        raise HTTPException(status_code=400, detail="Only PDFs allowed")
    
    # Store file temporarily
    file_path = f"/tmp/{uuid.uuid4()}_{file.filename}"
    with open(file_path, "wb") as buffer:
        buffer.write(await file.read())
    
    # Create job entry
    job_id = str(uuid.uuid4())
    
    # Queue extraction task
    extract_and_translate.delay(job_id, file_path)
    
    return {"job_id": job_id, "status": "queued"}

# ============================================
# 2. TRANSLATION ENDPOINT
# ============================================
@app.post("/api/v1/translate")
async def translate(request: TranslateRequest):
    """
    Translate PDF and customize tone
    """
    job_id = request.job_id
    target_language = request.target_language
    tone = request.tone  # User's tone specification
    
    # Get extracted text from database
    extraction = db.get_extraction(job_id)
    
    # Translate each block
    translated_blocks = []
    for block in extraction.blocks:
        # Step 1: Primary translation via DeepL
        translated_text = await translator.translate_text(
            block.text,
            target_lang=target_language
        )
        
        # Step 2: Tone customization via Claude Haiku
        if tone:
            tone_adjusted = await customize_tone(
                translated_text,
                tone,
                block.context
            )
            translated_blocks.append(tone_adjusted)
        else:
            translated_blocks.append(translated_text)
    
    # Store translation results
    translation_id = db.save_translation(job_id, translated_blocks)
    
    return {"translation_id": translation_id, "status": "complete"}

# ============================================
# 3. TONE CUSTOMIZATION HELPER
# ============================================
async def customize_tone(
    text: str,
    tone_description: str,
    context: str
) -> str:
    """
    Use Claude Haiku to adjust tone
    """
    prompt = f"""
You are a language expert specializing in tone adjustment.

Current text: "{text}"
Target tone: {tone_description}
Context: {context}

Rewrite the text in the target tone, preserving all meaning.
Return ONLY the rewritten text.
"""
    
    response = llm_client.messages.create(
        model="claude-3-5-haiku-20241022",
        max_tokens=500,
        messages=[{"role": "user", "content": prompt}]
    )
    
    return response.content[0].text

# ============================================
# 4. ASYNC EXTRACTION JOB (Celery)
# ============================================
@celery_app.task
def extract_and_translate(job_id: str, pdf_path: str):
    """
    Heavy lifting: PDF extraction using PyMuPDF
    Runs asynchronously, doesn't block API
    """
    try:
        # Extract text with layout info
        doc = fitz.open(pdf_path)
        blocks = []
        
        for page_num in range(len(doc)):
            page = doc[page_num]
            text_dict = page.get_text("dict")
            
            for block in text_dict["blocks"]:
                if block["type"] == 0:  # Text block
                    blocks.append({
                        "text": "".join([line for line in block["lines"]]),
                        "bbox": block["bbox"],
                        "page": page_num
                    })
        
        # Save extraction results
        db.save_extraction(job_id, blocks)
        
        # Update job status
        db.update_job_status(job_id, "ready_for_translation")
        
    except Exception as e:
        db.update_job_status(job_id, "error", str(e))
        logger.error(f"Extraction failed for {job_id}: {e}")

# ============================================
# 5. DOWNLOAD ENDPOINT
# ============================================
@app.get("/api/v1/download/{translation_id}")
async def download_translation(translation_id: str):
    """
    Reconstruct PDF with translations and return for download
    """
    translation = db.get_translation(translation_id)
    original = db.get_extraction(translation.job_id)
    
    # Reconstruct PDF with translated text
    output_pdf = reconstruct_pdf(original, translation)
    
    return FileResponse(output_pdf, filename="translated.pdf")
```

### Deployment Architecture

**Local Development:**
```bash
# Terminal 1: FastAPI Backend
uvicorn main:app --reload --port 8000

# Terminal 2: React Frontend  
npm run dev  # Vite dev server on :3000

# Terminal 3: Celery Workers
celery -A tasks worker --loglevel=info

# Terminal 4: Redis (if not running as service)
redis-server
```

**Production:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AWS / Docker Environment               â”‚
â”‚                                         â”‚
â”‚  â”œâ”€ FastAPI Container (uvicorn)        â”‚
â”‚  â”œâ”€ Celery Worker Containers (auto)    â”‚
â”‚  â”œâ”€ Redis (AWS ElastiCache)            â”‚
â”‚  â”œâ”€ PostgreSQL (AWS RDS)               â”‚
â”‚  â”œâ”€ S3 (File Storage)                  â”‚
â”‚  â””â”€ CloudFront (CDN)                   â”‚
â”‚                                         â”‚
â”‚  Frontend deployed to Vercel/Netlify   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4. PERFORMANCE PROJECTIONS ğŸ“Š

### Processing Speed for 100MB PDF (~500 pages)

```
PDF Extraction (PyMuPDF):        5-10 seconds
Translation (DeepL):              30-60 seconds (parallel, 10 pages/sec)
Tone Customization (Claude):      20-40 seconds (parallel batched)
PDF Reconstruction:               5-10 seconds
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total Time (with parallelization): ~45-75 seconds
User Experience: "Translating..." progress bar

Total Time (without parallelization): ~60-120 seconds
(If sequential, but we'll parallelize)
```

### Cost Projection per 100MB PDF

```
DeepL Translation:     ~$1.50 (500 pages Ã— 100 words = 50,000 words)
Claude Tone Adjustment: ~$0.10 (120K tokens)
LlamaParse (if needed): $0 (using PyMuPDF for digital)
S3 Storage:            ~$0.02 (temporary storage)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total per document: ~$1.62

Monthly (1000 docs): ~$1,620
Yearly (12,000 docs): ~$19,440
```

**Revenue Model Suggestion:**
- Free tier: 5 documents/month (test)
- Pro: $15/month = 100 documents (cost: $16.20, margin: -$1.20)
- Enterprise: $99/month = unlimited (need better margins)

*Note: Pricing needs to be competitive; adjust based on market research*

---

## 5. IMPLEMENTATION ROADMAP ğŸ—ºï¸

### Phase 1: MVP (Weeks 1-4)
âœ… FastAPI backend with PyMuPDF extraction
âœ… DeepL translation integration
âœ… React frontend with basic upload + download
âœ… Claude Haiku tone customization (optional)

### Phase 2: UX Enhancement (Weeks 5-6)
âœ… Dual-view display with synchronized highlighting
âœ… Real-time progress feedback
âœ… Drag-and-drop upload
âœ… User accounts + history

### Phase 3: Production Ready (Weeks 7-8)
âœ… LlamaParse integration for scanned PDFs
âœ… Database (PostgreSQL) for job tracking
âœ… Error handling + retry logic
âœ… Rate limiting + authentication
âœ… Monitoring + analytics

---

## 6. KEY TECH DECISIONS SUMMARY âœ…

| Decision | Choice | Why |
|----------|--------|-----|
| **LLM for Tone** | Claude 3.5 Haiku | Fastest + Cheapest for lightweight tasks |
| **PDF Extraction** | PyMuPDF (primary) + LlamaParse (fallback) | Free + fast for digital; AI OCR for scanned |
| **Translation** | DeepL (primary) | Best quality (alternative: Claude + DeepL combo) |
| **Frontend** | React + shadcn/ui | Your preference, great ecosystem |
| **Backend** | FastAPI | Perfect for async, high-performance Python |
| **Job Queue** | Celery + Redis | Handles async PDF processing |
| **Database** | PostgreSQL | Reliable, good for analytics |
| **Storage** | AWS S3 | Scalable, secure file storage |

---

## Questions to Validate

Before implementation, consider:

1. **Tone Customization:** How much control should users have?
   - Simple presets (Formal/Casual/Technical)?
   - Free-form description field?
   - Both?

2. **Quality Expectations:** If Claude tone adjustment changes meaning, acceptable?
   - Safeguard: Always show both versions (before/after tone)?

3. **Pricing Model:** How to monetize given low costs?
   - Per-document?
   - Subscription?
   - Freemium?

4. **Scanned PDF Strategy:** Auto-detect and use LlamaParse, or ask user first?

---

## References

**LLM Comparisons:** Anthropic, Google DeepMind, OpenAI docs [2025]  
**PDF Tools:** PyMuPDF, LlamaParse, benchmark studies [2025]  
**Research Papers:**
- SCALE Framework (LLM + TM integration): arxiv.org/abs/2309.17061
- On-the-fly Fusion (MT + LLM): arxiv.org/abs/2311.08306
- OCR vs Parsing Comparison: arxiv.org/abs/2407.04577

---

**Status:** Ready for Product Brief and detailed PRD planning  
**Next Phase:** Product Brief to establish strategic positioning and goals

