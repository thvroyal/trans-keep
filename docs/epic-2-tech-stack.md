# Epic 2: Core Translation Pipeline - Tech Stack & Architecture

**Epic:** 2  
**Title:** Core Translation Pipeline ğŸ”„  
**Stories:** 2.1 - 2.5  
**Duration:** 5 days (Dec 9-13)  
**Status:** contexted  
**Created:** November 15, 2025

---

## Overview

Implement the complete translation pipeline: file upload, PDF extraction, translation via DeepL, task orchestration with Celery, and real-time status tracking.

---

## ğŸ“¦ Tech Stack by Component

### **File Upload & Storage Stack**

| Component | Technology | Version | Why | Usage |
|-----------|------------|---------|-----|-------|
| **Upload Handler** | FastAPI File | Built-in | Type-safe multipart uploads | Story 2.1 |
| **File Validation** | Pydantic BaseModel | 2.5+ | Request validation | Story 2.1 |
| **S3 Client** | boto3 | 1.29+ | AWS SDK for Python | Story 2.1 |
| **Local S3** | MinIO | Latest | S3-compatible local storage | Story 2.1 (dev) |
| **Prod S3** | AWS S3 | - | Production file storage | Story 2.1 (prod) |
| **Chunked Upload** | Python streams | - | Handle 100MB files efficiently | Story 2.1 |
| **Async Upload** | aiofiles | Latest | Non-blocking file I/O | Story 2.1 |

### **PDF Processing Stack**

| Component | Technology | Version | Why | Usage |
|-----------|------------|---------|-----|-------|
| **PDF Library** | PyMuPDF (fitz) | 1.23+ | Fast text extraction with coordinates | Story 2.2 |
| **Text Extraction** | PyMuPDF blocks | - | Per-page block extraction | Story 2.2 |
| **Coordinate System** | Normalized percentages | - | Layout-preserving coordinates | Story 2.2 |
| **Performance** | Multi-threading | - | Parallel page processing | Story 2.2 |
| **Caching** | Redis | 7 | Cache extracted blocks (24h) | Story 2.2 |
| **Memory** | Generators | - | Stream large PDFs | Story 2.2 |

### **Translation API Stack**

| Component | Technology | Version | Why | Usage |
|-----------|------------|---------|-----|-------|
| **Translation API** | DeepL Python Client | 1.16+ | High-quality translations | Story 2.3 |
| **Supported Languages** | ENâ†’JA, ENâ†’VI, ENâ†’ZH | - | User-selected languages | Story 2.3 |
| **Batch Processing** | DeepL Batch API | - | 10 blocks per API call | Story 2.3 |
| **Error Handling** | Retry logic | - | Exponential backoff on rate limit | Story 2.3 |
| **Cost Tracking** | Custom logging | - | Track API costs per document | Story 2.3 |
| **Budget** | $0.15 per job | - | 3 translations max per user/day | Story 2.3 |

### **Task Queue Stack**

| Component | Technology | Version | Why | Usage |
|-----------|------------|---------|-----|-------|
| **Task Queue** | Celery | 5.3+ | Distributed async tasks | Story 2.4 |
| **Message Broker** | Redis | 7 | Celery broker communication | Story 2.4 |
| **Task Orchestration** | Celery Signatures | - | Chain extraction â†’ translate â†’ tone â†’ reconstruct | Story 2.4 |
| **Error Handling** | Celery Retry | - | Automatic retry with backoff | Story 2.4 |
| **Monitoring** | Celery Events | - | Real-time task monitoring | Story 2.4 |
| **Flower UI** | Flower | Latest | Web-based task monitoring | Story 2.4 |
| **Worker Pool** | prefork | - | Process pool for parallelization | Story 2.4 |

### **Job Status Tracking Stack**

| Component | Technology | Version | Why | Usage |
|-----------|------------|---------|-----|-------|
| **Status Storage** | PostgreSQL | 15 | Persistent job status | Story 2.5 |
| **Status Model** | SQLAlchemy ORM | 2.0+ | Type-safe status queries | Story 2.5 |
| **Status Updates** | Celery Task Hooks | - | Update status after each step | Story 2.5 |
| **Progress Calculation** | SQL Queries | - | Count processed vs total blocks | Story 2.5 |
| **ETA Calculation** | Custom formula | - | Estimate time to completion | Story 2.5 |
| **Frontend Polling** | TanStack Query | Latest | Efficient polling with caching | Story 2.5 |
| **Polling Interval** | 2 seconds | - | Real-time progress updates | Story 2.5 |

---

## ğŸ”„ Epic 2 Story & Tech Stack Mapping

### **Story 2.1: File Upload Endpoint**
```
Technologies:
â”œâ”€â”€ FastAPI (multipart upload)
â”œâ”€â”€ Pydantic (request validation)
â”œâ”€â”€ boto3 (S3 upload)
â”œâ”€â”€ PostgreSQL (translation record)
â”œâ”€â”€ SQLAlchemy (ORM)
â””â”€â”€ Error handling & validation
```

**Key Files:**
- `backend/app/routers/upload.py` - Upload endpoint
- `backend/app/schemas/upload.py` - Request/response models
- `backend/app/services/s3_service.py` - S3 operations
- `backend/tests/test_upload.py` - Integration tests

### **Story 2.2: PDF Extraction with PyMuPDF**
```
Technologies:
â”œâ”€â”€ PyMuPDF (text extraction)
â”œâ”€â”€ Redis (block caching)
â”œâ”€â”€ Multi-threading (parallelization)
â”œâ”€â”€ PostgreSQL (block storage)
â””â”€â”€ SQLAlchemy (ORM)
```

**Key Files:**
- `backend/app/services/pdf_service.py` - PDF extraction
- `backend/app/tasks/extract_pdf.py` - Celery task
- `backend/app/schemas/pdf.py` - Block data models
- `backend/tests/test_pdf_extraction.py` - Tests

### **Story 2.3: DeepL Translation Integration**
```
Technologies:
â”œâ”€â”€ DeepL API client (translation)
â”œâ”€â”€ Batch processing (10 blocks/call)
â”œâ”€â”€ Celery (async tasks)
â”œâ”€â”€ Error handling (rate limit retry)
â””â”€â”€ Cost tracking (logging)
```

**Key Files:**
- `backend/app/services/translation_service.py` - DeepL wrapper
- `backend/app/tasks/translate_blocks.py` - Translation task
- Cost tracking in logs & database

### **Story 2.4: Celery Job Queue Setup**
```
Technologies:
â”œâ”€â”€ Celery (task orchestration)
â”œâ”€â”€ Redis (broker)
â”œâ”€â”€ SQLAlchemy (status persistence)
â”œâ”€â”€ Flower (monitoring)
â””â”€â”€ Task chains (workflow)
```

**Key Files:**
- `backend/app/celery_app.py` - Celery configuration
- `backend/app/tasks/*.py` - All task definitions
- Pipeline: extract â†’ translate â†’ tone â†’ reconstruct

### **Story 2.5: Status Polling Endpoint**
```
Technologies:
â”œâ”€â”€ FastAPI (GET /status/{job_id})
â”œâ”€â”€ PostgreSQL (status queries)
â”œâ”€â”€ SQLAlchemy (ORM)
â”œâ”€â”€ TanStack Query (frontend polling)
â””â”€â”€ Real-time progress UI
```

**Key Files:**
- `backend/app/routers/translation.py` - Status endpoint
- `frontend/src/hooks/useTranslation.ts` - Status polling hook
- `frontend/src/pages/ProcessingPage.tsx` - Progress UI

---

## ğŸ“Š Data Flow Architecture

### **Complete Translation Pipeline**

```
1. USER UPLOADS PDF
   â””â”€ FastAPI endpoint receives multipart upload
   â””â”€ Pydantic validates file (type, size)
   â””â”€ boto3 uploads to S3
   â””â”€ SQLAlchemy creates Translation record (status='pending')
   â””â”€ Returns job_id to frontend
   â””â”€ Triggers extract_and_translate Celery task

2. EXTRACT PDF BLOCKS
   â”œâ”€ Celery task: extract_pdf_task(job_id)
   â”œâ”€ PyMuPDF reads PDF from S3
   â”œâ”€ Extracts text blocks with coordinates
   â”œâ”€ Stores in Redis cache (TTL 24h)
   â”œâ”€ Updates DB: DocumentBlocks table
   â”œâ”€ Updates status: 'extracting' â†’ 'extracted'
   â””â”€ Yields to next task in chain

3. TRANSLATE BLOCKS
   â”œâ”€ Celery task: translate_blocks_task(job_id)
   â”œâ”€ Gets blocks from Redis cache
   â”œâ”€ Batches 10 blocks per API call
   â”œâ”€ Calls DeepL API (ENâ†’JA/VI/ZH)
   â”œâ”€ Stores translations in DocumentBlocks
   â”œâ”€ Updates status: 'translating' â†’ 'translated'
   â”œâ”€ Tracks API costs in logs
   â””â”€ Yields to next task in chain

4. CUSTOMIZE TONE (Optional)
   â”œâ”€ Celery task: customize_tone_task(job_id)
   â”œâ”€ Gets translations from DB
   â”œâ”€ Calls Claude Haiku API with tone prompt
   â”œâ”€ Updates translations with tone version
   â”œâ”€ Updates status: 'tone_customizing' â†’ 'tone_customized'
   â””â”€ Yields to final task

5. RECONSTRUCT PDF
   â”œâ”€ Celery task: reconstruct_pdf_task(job_id)
   â”œâ”€ Gets original PDF from S3
   â”œâ”€ Gets final translations from DB
   â”œâ”€ PyMuPDF reconstructs with new text
   â”œâ”€ Uploads final PDF to S3
   â”œâ”€ Updates status: 'reconstructing' â†’ 'completed'
   â””â”€ Task chain completes

6. FRONTEND POLLS STATUS
   â”œâ”€ TanStack Query every 2 seconds
   â”œâ”€ GET /api/v1/status/{job_id}
   â”œâ”€ Receives: status, progress%, ETA
   â”œâ”€ Updates ProcessingPage UI
   â”œâ”€ Stops polling when status='completed'
   â””â”€ Redirects to ReviewPage
```

---

## ğŸ—„ï¸ Database Schema for Epic 2

### **Translations Table**
```sql
CREATE TABLE translations (
  id UUID PRIMARY KEY,
  user_id UUID NOT NULL REFERENCES users(id),
  status VARCHAR(50),  -- pending, extracting, extracted, translating, translated, tone_customizing, tone_customized, reconstructing, completed, failed
  progress_percent INT DEFAULT 0,
  total_blocks INT,
  processed_blocks INT,
  original_pdf_path VARCHAR(500),
  translated_pdf_path VARCHAR(500),
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP,
  completed_at TIMESTAMP,
  error_message TEXT,
  deeplapi_cost DECIMAL(10, 6),
  claude_cost DECIMAL(10, 6)
);
```

### **DocumentBlocks Table**
```sql
CREATE TABLE document_blocks (
  id UUID PRIMARY KEY,
  translation_id UUID NOT NULL REFERENCES translations(id) ON DELETE CASCADE,
  page_number INT NOT NULL,
  block_number INT NOT NULL,
  original_text TEXT NOT NULL,
  translated_text TEXT,
  tone_customized_text TEXT,
  coordinates JSONB,  -- {x, y, width, height}
  font_size INT,
  is_processed BOOLEAN DEFAULT FALSE,
  created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_translation_id ON document_blocks(translation_id);
CREATE INDEX idx_page_block ON document_blocks(translation_id, page_number, block_number);
```

---

## ğŸš€ Deployment Configuration

### **Local Development (Docker Compose)**
```yaml
services:
  backend:
    environment:
      - DATABASE_URL=postgresql://postgres:postgres@postgres:5432/transkeep
      - REDIS_URL=redis://redis:6379
      - DEEPL_API_KEY=${DEEPL_API_KEY}
      - CLAUDE_API_KEY=${CLAUDE_API_KEY}
  
  celery_worker:
    command: celery -A app.celery_app worker -l info
    depends_on:
      - redis
      - postgres

  flower:
    image: mher/flower:latest
    ports:
      - 5555:5555
    environment:
      - CELERY_BROKER_URL=redis://redis:6379
```

### **Production (AWS)**
- **Backend:** ECS Fargate with Celery workers
- **Database:** RDS PostgreSQL (multi-AZ)
- **Cache:** ElastiCache Redis (cluster mode enabled)
- **File Storage:** S3 buckets with lifecycle policies (delete after 24h)
- **Monitoring:** CloudWatch logs + metrics
- **API Keys:** AWS Secrets Manager

---

## ğŸ“‹ API Endpoints for Epic 2

### **Story 2.1: Upload**
```
POST /api/v1/upload
  Content-Type: multipart/form-data
  Body: file (PDF)
  Response: {
    "job_id": "uuid",
    "status": "pending",
    "message": "File uploaded successfully"
  }
```

### **Story 2.5: Status**
```
GET /api/v1/status/{job_id}
  Response: {
    "job_id": "uuid",
    "status": "translating",
    "progress": 45,
    "total_blocks": 100,
    "processed_blocks": 45,
    "eta_seconds": 120,
    "page_count": 10
  }
```

---

## ğŸ¯ Success Criteria for Epic 2

**All stories in Epic 2 must satisfy:**

- âœ… Upload PDF up to 100MB reliably
- âœ… Extract text blocks with accurate coordinates
- âœ… Translate via DeepL with batch optimization
- âœ… Celery pipeline orchestrates all tasks
- âœ… Status updates in real-time
- âœ… Works for 10, 100, 500+ page PDFs
- âœ… Processing time: 10-90 seconds depending on size
- âœ… Error recovery and retry working
- âœ… Costs tracked and logged
- âœ… Flower monitoring available
- âœ… All tests passing
- âœ… No data loss on failures

---

## ğŸ“š External Resources

- [DeepL Python Docs](https://github.com/DeepLcom/deepl-python)
- [Celery Documentation](https://docs.celeryproject.io)
- [PyMuPDF Documentation](https://pymupdf.readthedocs.io)
- [boto3 S3 Reference](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html)
- [Flower Monitoring](https://flower.readthedocs.io)

---

**Epic 2 Tech Stack Status:** âœ… **CONTEXTED**

All technologies identified for Stories 2.1-2.5.
Ready for implementation.

**Created:** November 15, 2025  
**Last Updated:** November 15, 2025

